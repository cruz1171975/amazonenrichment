from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any

from ..compliance.blocklist import iter_blocked_terms
from ..compliance.scanner import ScanConfig, scan_listing_fields
from ..listing.amazon_fields import (
    BACKEND_SEARCH_TERMS_BYTE_LIMIT,
    BULLET_CHAR_LIMIT,
    DESCRIPTION_CHAR_LIMIT,
    TITLE_CHAR_LIMIT,
)
from .base import LlmClient, LlmRequest
from .prompts import build_listing_rewrite_prompt


def _clean(s: Any) -> str:
    if not isinstance(s, str):
        return ""
    return " ".join(s.strip().split())


def _truncate_chars(s: str, limit: int) -> str:
    s = s.strip()
    if len(s) <= limit:
        return s
    return s[: max(0, limit - 1)].rstrip() + "â€¦"


def _truncate_utf8_bytes_space_separated(s: str, limit: int) -> str:
    tokens = [t for t in s.split() if t]
    out: list[str] = []
    for tok in tokens:
        candidate = (" ".join(out + [tok])).strip()
        if len(candidate.encode("utf-8")) <= limit:
            out.append(tok)
        else:
            break
    return " ".join(out).strip()


def _normalize_listing_payload(payload: dict[str, Any]) -> dict[str, Any]:
    title = _truncate_chars(_clean(payload.get("title")), TITLE_CHAR_LIMIT)
    bullets_in = payload.get("bullets") if isinstance(payload.get("bullets"), list) else []
    bullets = []
    for b in bullets_in[:5]:
        bullets.append(_truncate_chars(_clean(b), BULLET_CHAR_LIMIT))
    description = _truncate_chars(_clean(payload.get("description")), DESCRIPTION_CHAR_LIMIT)
    backend = _truncate_utf8_bytes_space_separated(
        _clean(payload.get("backend_search_terms")), BACKEND_SEARCH_TERMS_BYTE_LIMIT
    )
    out: dict[str, Any] = {
        "title": title,
        "bullets": bullets,
        "description": description,
        "backend_search_terms": backend,
    }
    if isinstance(payload.get("a_plus_markdown"), str):
        out["a_plus_markdown"] = payload["a_plus_markdown"]
    if isinstance(payload.get("a_plus"), (dict, list)):
        out["a_plus"] = payload["a_plus"]
    return out


def _forbidden_terms_for_prompt() -> list[str]:
    terms = [t.term for t in iter_blocked_terms()]
    # Keep prompt smaller: unique, stable order.
    seen = set()
    out = []
    for t in terms:
        key = t.lower()
        if key in seen:
            continue
        seen.add(key)
        out.append(t)
    return out


@dataclass(frozen=True)
class LlmListingResult:
    listing: dict[str, Any]
    compliance_status: str  # "pass" | "fail"
    compliance_findings: list[dict[str, str]]
    used_fallback: bool


def generate_listing_with_llm(
    *,
    facts: dict[str, Any],
    base_listing: dict[str, Any],
    client: LlmClient,
    model: str,
    max_attempts: int = 2,
) -> LlmListingResult:
    hard_rules = [
        "No antimicrobial, pesticide, medical, or drug claims.",
        "No absolute safety claims (e.g., non-toxic, chemical-free, safe for everyone).",
        "No environmental claims unless substantiated (avoid eco-friendly/biodegradable/etc.).",
        "No grade terms unless present in facts.product_name (Shopify title).",
        "Do not mention EPA/FDA approval unless explicitly present in facts.",
    ]
    forbidden = _forbidden_terms_for_prompt()
    allow_name = _clean(facts.get("product_name")) or None
    config = ScanConfig(allow_grade_terms_from_product_name=allow_name)

    used_fallback = False
    last_listing = _normalize_listing_payload(base_listing)
    last_findings = scan_listing_fields(last_listing, config=config)

    for _ in range(max_attempts):
        prompt = build_listing_rewrite_prompt(
            facts=facts,
            base_listing=last_listing,
            forbidden_terms=forbidden,
            hard_rules=hard_rules,
        )
        resp = client.generate(LlmRequest(model=model, prompt=prompt))
        try:
            parsed = json.loads(resp.text)
        except json.JSONDecodeError:
            used_fallback = True
            break

        if not isinstance(parsed, dict):
            used_fallback = True
            break

        candidate = _normalize_listing_payload(parsed)
        findings = scan_listing_fields(candidate, config=config)
        if any(f.severity == "hard" for f in findings):
            last_listing = candidate
            last_findings = findings
            continue

        return LlmListingResult(
            listing=candidate,
            compliance_status="pass",
            compliance_findings=[f.to_dict() for f in findings],
            used_fallback=False,
        )

    # Safe fallback: return the base listing (assumed generated by our deterministic generator).
    used_fallback = True
    fallback_findings = scan_listing_fields(base_listing, config=config)
    return LlmListingResult(
        listing=base_listing,
        compliance_status="fail" if any(f.severity == "hard" for f in fallback_findings) else "pass",
        compliance_findings=[f.to_dict() for f in fallback_findings],
        used_fallback=used_fallback,
    )

